/**
 * Autogenerated by Thrift Compiler (0.9.0)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package com.cloudera.impala.thrift;

import org.apache.commons.lang.builder.HashCodeBuilder;
import org.apache.thrift.scheme.IScheme;
import org.apache.thrift.scheme.SchemeFactory;
import org.apache.thrift.scheme.StandardScheme;

import org.apache.thrift.scheme.TupleScheme;
import org.apache.thrift.protocol.TTupleProtocol;
import org.apache.thrift.protocol.TProtocolException;
import org.apache.thrift.EncodingUtils;
import org.apache.thrift.TException;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.nio.ByteBuffer;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class THdfsFileSplit implements org.apache.thrift.TBase<THdfsFileSplit, THdfsFileSplit._Fields>, java.io.Serializable, Cloneable {
  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("THdfsFileSplit");

  private static final org.apache.thrift.protocol.TField FILE_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField("file_name", org.apache.thrift.protocol.TType.STRING, (short)1);
  private static final org.apache.thrift.protocol.TField OFFSET_FIELD_DESC = new org.apache.thrift.protocol.TField("offset", org.apache.thrift.protocol.TType.I64, (short)2);
  private static final org.apache.thrift.protocol.TField LENGTH_FIELD_DESC = new org.apache.thrift.protocol.TField("length", org.apache.thrift.protocol.TType.I64, (short)3);
  private static final org.apache.thrift.protocol.TField PARTITION_ID_FIELD_DESC = new org.apache.thrift.protocol.TField("partition_id", org.apache.thrift.protocol.TType.I64, (short)4);
  private static final org.apache.thrift.protocol.TField FILE_LENGTH_FIELD_DESC = new org.apache.thrift.protocol.TField("file_length", org.apache.thrift.protocol.TType.I64, (short)5);
  private static final org.apache.thrift.protocol.TField FILE_COMPRESSION_FIELD_DESC = new org.apache.thrift.protocol.TField("file_compression", org.apache.thrift.protocol.TType.I32, (short)6);

  private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
  static {
    schemes.put(StandardScheme.class, new THdfsFileSplitStandardSchemeFactory());
    schemes.put(TupleScheme.class, new THdfsFileSplitTupleSchemeFactory());
  }

  public String file_name; // required
  public long offset; // required
  public long length; // required
  public long partition_id; // required
  public long file_length; // required
  /**
   * 
   * @see com.cloudera.impala.thrift.THdfsCompression
   */
  public com.cloudera.impala.thrift.THdfsCompression file_compression; // required

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
    FILE_NAME((short)1, "file_name"),
    OFFSET((short)2, "offset"),
    LENGTH((short)3, "length"),
    PARTITION_ID((short)4, "partition_id"),
    FILE_LENGTH((short)5, "file_length"),
    /**
     * 
     * @see com.cloudera.impala.thrift.THdfsCompression
     */
    FILE_COMPRESSION((short)6, "file_compression");

    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      switch(fieldId) {
        case 1: // FILE_NAME
          return FILE_NAME;
        case 2: // OFFSET
          return OFFSET;
        case 3: // LENGTH
          return LENGTH;
        case 4: // PARTITION_ID
          return PARTITION_ID;
        case 5: // FILE_LENGTH
          return FILE_LENGTH;
        case 6: // FILE_COMPRESSION
          return FILE_COMPRESSION;
        default:
          return null;
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final int __OFFSET_ISSET_ID = 0;
  private static final int __LENGTH_ISSET_ID = 1;
  private static final int __PARTITION_ID_ISSET_ID = 2;
  private static final int __FILE_LENGTH_ISSET_ID = 3;
  private byte __isset_bitfield = 0;
  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
  static {
    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
    tmpMap.put(_Fields.FILE_NAME, new org.apache.thrift.meta_data.FieldMetaData("file_name", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    tmpMap.put(_Fields.OFFSET, new org.apache.thrift.meta_data.FieldMetaData("offset", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
    tmpMap.put(_Fields.LENGTH, new org.apache.thrift.meta_data.FieldMetaData("length", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
    tmpMap.put(_Fields.PARTITION_ID, new org.apache.thrift.meta_data.FieldMetaData("partition_id", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
    tmpMap.put(_Fields.FILE_LENGTH, new org.apache.thrift.meta_data.FieldMetaData("file_length", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
    tmpMap.put(_Fields.FILE_COMPRESSION, new org.apache.thrift.meta_data.FieldMetaData("file_compression", org.apache.thrift.TFieldRequirementType.REQUIRED, 
        new org.apache.thrift.meta_data.EnumMetaData(org.apache.thrift.protocol.TType.ENUM, com.cloudera.impala.thrift.THdfsCompression.class)));
    metaDataMap = Collections.unmodifiableMap(tmpMap);
    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(THdfsFileSplit.class, metaDataMap);
  }

  public THdfsFileSplit() {
  }

  public THdfsFileSplit(
    String file_name,
    long offset,
    long length,
    long partition_id,
    long file_length,
    com.cloudera.impala.thrift.THdfsCompression file_compression)
  {
    this();
    this.file_name = file_name;
    this.offset = offset;
    setOffsetIsSet(true);
    this.length = length;
    setLengthIsSet(true);
    this.partition_id = partition_id;
    setPartition_idIsSet(true);
    this.file_length = file_length;
    setFile_lengthIsSet(true);
    this.file_compression = file_compression;
  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public THdfsFileSplit(THdfsFileSplit other) {
    __isset_bitfield = other.__isset_bitfield;
    if (other.isSetFile_name()) {
      this.file_name = other.file_name;
    }
    this.offset = other.offset;
    this.length = other.length;
    this.partition_id = other.partition_id;
    this.file_length = other.file_length;
    if (other.isSetFile_compression()) {
      this.file_compression = other.file_compression;
    }
  }

  public THdfsFileSplit deepCopy() {
    return new THdfsFileSplit(this);
  }

  @Override
  public void clear() {
    this.file_name = null;
    setOffsetIsSet(false);
    this.offset = 0;
    setLengthIsSet(false);
    this.length = 0;
    setPartition_idIsSet(false);
    this.partition_id = 0;
    setFile_lengthIsSet(false);
    this.file_length = 0;
    this.file_compression = null;
  }

  public String getFile_name() {
    return this.file_name;
  }

  public THdfsFileSplit setFile_name(String file_name) {
    this.file_name = file_name;
    return this;
  }

  public void unsetFile_name() {
    this.file_name = null;
  }

  /** Returns true if field file_name is set (has been assigned a value) and false otherwise */
  public boolean isSetFile_name() {
    return this.file_name != null;
  }

  public void setFile_nameIsSet(boolean value) {
    if (!value) {
      this.file_name = null;
    }
  }

  public long getOffset() {
    return this.offset;
  }

  public THdfsFileSplit setOffset(long offset) {
    this.offset = offset;
    setOffsetIsSet(true);
    return this;
  }

  public void unsetOffset() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __OFFSET_ISSET_ID);
  }

  /** Returns true if field offset is set (has been assigned a value) and false otherwise */
  public boolean isSetOffset() {
    return EncodingUtils.testBit(__isset_bitfield, __OFFSET_ISSET_ID);
  }

  public void setOffsetIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __OFFSET_ISSET_ID, value);
  }

  public long getLength() {
    return this.length;
  }

  public THdfsFileSplit setLength(long length) {
    this.length = length;
    setLengthIsSet(true);
    return this;
  }

  public void unsetLength() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __LENGTH_ISSET_ID);
  }

  /** Returns true if field length is set (has been assigned a value) and false otherwise */
  public boolean isSetLength() {
    return EncodingUtils.testBit(__isset_bitfield, __LENGTH_ISSET_ID);
  }

  public void setLengthIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __LENGTH_ISSET_ID, value);
  }

  public long getPartition_id() {
    return this.partition_id;
  }

  public THdfsFileSplit setPartition_id(long partition_id) {
    this.partition_id = partition_id;
    setPartition_idIsSet(true);
    return this;
  }

  public void unsetPartition_id() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __PARTITION_ID_ISSET_ID);
  }

  /** Returns true if field partition_id is set (has been assigned a value) and false otherwise */
  public boolean isSetPartition_id() {
    return EncodingUtils.testBit(__isset_bitfield, __PARTITION_ID_ISSET_ID);
  }

  public void setPartition_idIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __PARTITION_ID_ISSET_ID, value);
  }

  public long getFile_length() {
    return this.file_length;
  }

  public THdfsFileSplit setFile_length(long file_length) {
    this.file_length = file_length;
    setFile_lengthIsSet(true);
    return this;
  }

  public void unsetFile_length() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __FILE_LENGTH_ISSET_ID);
  }

  /** Returns true if field file_length is set (has been assigned a value) and false otherwise */
  public boolean isSetFile_length() {
    return EncodingUtils.testBit(__isset_bitfield, __FILE_LENGTH_ISSET_ID);
  }

  public void setFile_lengthIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __FILE_LENGTH_ISSET_ID, value);
  }

  /**
   * 
   * @see com.cloudera.impala.thrift.THdfsCompression
   */
  public com.cloudera.impala.thrift.THdfsCompression getFile_compression() {
    return this.file_compression;
  }

  /**
   * 
   * @see com.cloudera.impala.thrift.THdfsCompression
   */
  public THdfsFileSplit setFile_compression(com.cloudera.impala.thrift.THdfsCompression file_compression) {
    this.file_compression = file_compression;
    return this;
  }

  public void unsetFile_compression() {
    this.file_compression = null;
  }

  /** Returns true if field file_compression is set (has been assigned a value) and false otherwise */
  public boolean isSetFile_compression() {
    return this.file_compression != null;
  }

  public void setFile_compressionIsSet(boolean value) {
    if (!value) {
      this.file_compression = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case FILE_NAME:
      if (value == null) {
        unsetFile_name();
      } else {
        setFile_name((String)value);
      }
      break;

    case OFFSET:
      if (value == null) {
        unsetOffset();
      } else {
        setOffset((Long)value);
      }
      break;

    case LENGTH:
      if (value == null) {
        unsetLength();
      } else {
        setLength((Long)value);
      }
      break;

    case PARTITION_ID:
      if (value == null) {
        unsetPartition_id();
      } else {
        setPartition_id((Long)value);
      }
      break;

    case FILE_LENGTH:
      if (value == null) {
        unsetFile_length();
      } else {
        setFile_length((Long)value);
      }
      break;

    case FILE_COMPRESSION:
      if (value == null) {
        unsetFile_compression();
      } else {
        setFile_compression((com.cloudera.impala.thrift.THdfsCompression)value);
      }
      break;

    }
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case FILE_NAME:
      return getFile_name();

    case OFFSET:
      return Long.valueOf(getOffset());

    case LENGTH:
      return Long.valueOf(getLength());

    case PARTITION_ID:
      return Long.valueOf(getPartition_id());

    case FILE_LENGTH:
      return Long.valueOf(getFile_length());

    case FILE_COMPRESSION:
      return getFile_compression();

    }
    throw new IllegalStateException();
  }

  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case FILE_NAME:
      return isSetFile_name();
    case OFFSET:
      return isSetOffset();
    case LENGTH:
      return isSetLength();
    case PARTITION_ID:
      return isSetPartition_id();
    case FILE_LENGTH:
      return isSetFile_length();
    case FILE_COMPRESSION:
      return isSetFile_compression();
    }
    throw new IllegalStateException();
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof THdfsFileSplit)
      return this.equals((THdfsFileSplit)that);
    return false;
  }

  public boolean equals(THdfsFileSplit that) {
    if (that == null)
      return false;

    boolean this_present_file_name = true && this.isSetFile_name();
    boolean that_present_file_name = true && that.isSetFile_name();
    if (this_present_file_name || that_present_file_name) {
      if (!(this_present_file_name && that_present_file_name))
        return false;
      if (!this.file_name.equals(that.file_name))
        return false;
    }

    boolean this_present_offset = true;
    boolean that_present_offset = true;
    if (this_present_offset || that_present_offset) {
      if (!(this_present_offset && that_present_offset))
        return false;
      if (this.offset != that.offset)
        return false;
    }

    boolean this_present_length = true;
    boolean that_present_length = true;
    if (this_present_length || that_present_length) {
      if (!(this_present_length && that_present_length))
        return false;
      if (this.length != that.length)
        return false;
    }

    boolean this_present_partition_id = true;
    boolean that_present_partition_id = true;
    if (this_present_partition_id || that_present_partition_id) {
      if (!(this_present_partition_id && that_present_partition_id))
        return false;
      if (this.partition_id != that.partition_id)
        return false;
    }

    boolean this_present_file_length = true;
    boolean that_present_file_length = true;
    if (this_present_file_length || that_present_file_length) {
      if (!(this_present_file_length && that_present_file_length))
        return false;
      if (this.file_length != that.file_length)
        return false;
    }

    boolean this_present_file_compression = true && this.isSetFile_compression();
    boolean that_present_file_compression = true && that.isSetFile_compression();
    if (this_present_file_compression || that_present_file_compression) {
      if (!(this_present_file_compression && that_present_file_compression))
        return false;
      if (!this.file_compression.equals(that.file_compression))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    HashCodeBuilder builder = new HashCodeBuilder();

    boolean present_file_name = true && (isSetFile_name());
    builder.append(present_file_name);
    if (present_file_name)
      builder.append(file_name);

    boolean present_offset = true;
    builder.append(present_offset);
    if (present_offset)
      builder.append(offset);

    boolean present_length = true;
    builder.append(present_length);
    if (present_length)
      builder.append(length);

    boolean present_partition_id = true;
    builder.append(present_partition_id);
    if (present_partition_id)
      builder.append(partition_id);

    boolean present_file_length = true;
    builder.append(present_file_length);
    if (present_file_length)
      builder.append(file_length);

    boolean present_file_compression = true && (isSetFile_compression());
    builder.append(present_file_compression);
    if (present_file_compression)
      builder.append(file_compression.getValue());

    return builder.toHashCode();
  }

  public int compareTo(THdfsFileSplit other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    THdfsFileSplit typedOther = (THdfsFileSplit)other;

    lastComparison = Boolean.valueOf(isSetFile_name()).compareTo(typedOther.isSetFile_name());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetFile_name()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.file_name, typedOther.file_name);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetOffset()).compareTo(typedOther.isSetOffset());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetOffset()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.offset, typedOther.offset);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetLength()).compareTo(typedOther.isSetLength());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetLength()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.length, typedOther.length);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetPartition_id()).compareTo(typedOther.isSetPartition_id());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetPartition_id()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.partition_id, typedOther.partition_id);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetFile_length()).compareTo(typedOther.isSetFile_length());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetFile_length()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.file_length, typedOther.file_length);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetFile_compression()).compareTo(typedOther.isSetFile_compression());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetFile_compression()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.file_compression, typedOther.file_compression);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    return 0;
  }

  public _Fields fieldForId(int fieldId) {
    return _Fields.findByThriftId(fieldId);
  }

  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
  }

  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("THdfsFileSplit(");
    boolean first = true;

    sb.append("file_name:");
    if (this.file_name == null) {
      sb.append("null");
    } else {
      sb.append(this.file_name);
    }
    first = false;
    if (!first) sb.append(", ");
    sb.append("offset:");
    sb.append(this.offset);
    first = false;
    if (!first) sb.append(", ");
    sb.append("length:");
    sb.append(this.length);
    first = false;
    if (!first) sb.append(", ");
    sb.append("partition_id:");
    sb.append(this.partition_id);
    first = false;
    if (!first) sb.append(", ");
    sb.append("file_length:");
    sb.append(this.file_length);
    first = false;
    if (!first) sb.append(", ");
    sb.append("file_compression:");
    if (this.file_compression == null) {
      sb.append("null");
    } else {
      sb.append(this.file_compression);
    }
    first = false;
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws org.apache.thrift.TException {
    // check for required fields
    if (file_name == null) {
      throw new org.apache.thrift.protocol.TProtocolException("Required field 'file_name' was not present! Struct: " + toString());
    }
    // alas, we cannot check 'offset' because it's a primitive and you chose the non-beans generator.
    // alas, we cannot check 'length' because it's a primitive and you chose the non-beans generator.
    // alas, we cannot check 'partition_id' because it's a primitive and you chose the non-beans generator.
    // alas, we cannot check 'file_length' because it's a primitive and you chose the non-beans generator.
    if (file_compression == null) {
      throw new org.apache.thrift.protocol.TProtocolException("Required field 'file_compression' was not present! Struct: " + toString());
    }
    // check for sub-struct validity
  }

  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
    try {
      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
    try {
      // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
      __isset_bitfield = 0;
      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private static class THdfsFileSplitStandardSchemeFactory implements SchemeFactory {
    public THdfsFileSplitStandardScheme getScheme() {
      return new THdfsFileSplitStandardScheme();
    }
  }

  private static class THdfsFileSplitStandardScheme extends StandardScheme<THdfsFileSplit> {

    public void read(org.apache.thrift.protocol.TProtocol iprot, THdfsFileSplit struct) throws org.apache.thrift.TException {
      org.apache.thrift.protocol.TField schemeField;
      iprot.readStructBegin();
      while (true)
      {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
          break;
        }
        switch (schemeField.id) {
          case 1: // FILE_NAME
            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
              struct.file_name = iprot.readString();
              struct.setFile_nameIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 2: // OFFSET
            if (schemeField.type == org.apache.thrift.protocol.TType.I64) {
              struct.offset = iprot.readI64();
              struct.setOffsetIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 3: // LENGTH
            if (schemeField.type == org.apache.thrift.protocol.TType.I64) {
              struct.length = iprot.readI64();
              struct.setLengthIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 4: // PARTITION_ID
            if (schemeField.type == org.apache.thrift.protocol.TType.I64) {
              struct.partition_id = iprot.readI64();
              struct.setPartition_idIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 5: // FILE_LENGTH
            if (schemeField.type == org.apache.thrift.protocol.TType.I64) {
              struct.file_length = iprot.readI64();
              struct.setFile_lengthIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 6: // FILE_COMPRESSION
            if (schemeField.type == org.apache.thrift.protocol.TType.I32) {
              struct.file_compression = com.cloudera.impala.thrift.THdfsCompression.findByValue(iprot.readI32());
              struct.setFile_compressionIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          default:
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      if (!struct.isSetOffset()) {
        throw new org.apache.thrift.protocol.TProtocolException("Required field 'offset' was not found in serialized data! Struct: " + toString());
      }
      if (!struct.isSetLength()) {
        throw new org.apache.thrift.protocol.TProtocolException("Required field 'length' was not found in serialized data! Struct: " + toString());
      }
      if (!struct.isSetPartition_id()) {
        throw new org.apache.thrift.protocol.TProtocolException("Required field 'partition_id' was not found in serialized data! Struct: " + toString());
      }
      if (!struct.isSetFile_length()) {
        throw new org.apache.thrift.protocol.TProtocolException("Required field 'file_length' was not found in serialized data! Struct: " + toString());
      }
      struct.validate();
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot, THdfsFileSplit struct) throws org.apache.thrift.TException {
      struct.validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (struct.file_name != null) {
        oprot.writeFieldBegin(FILE_NAME_FIELD_DESC);
        oprot.writeString(struct.file_name);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(OFFSET_FIELD_DESC);
      oprot.writeI64(struct.offset);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(LENGTH_FIELD_DESC);
      oprot.writeI64(struct.length);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(PARTITION_ID_FIELD_DESC);
      oprot.writeI64(struct.partition_id);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(FILE_LENGTH_FIELD_DESC);
      oprot.writeI64(struct.file_length);
      oprot.writeFieldEnd();
      if (struct.file_compression != null) {
        oprot.writeFieldBegin(FILE_COMPRESSION_FIELD_DESC);
        oprot.writeI32(struct.file_compression.getValue());
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

  }

  private static class THdfsFileSplitTupleSchemeFactory implements SchemeFactory {
    public THdfsFileSplitTupleScheme getScheme() {
      return new THdfsFileSplitTupleScheme();
    }
  }

  private static class THdfsFileSplitTupleScheme extends TupleScheme<THdfsFileSplit> {

    @Override
    public void write(org.apache.thrift.protocol.TProtocol prot, THdfsFileSplit struct) throws org.apache.thrift.TException {
      TTupleProtocol oprot = (TTupleProtocol) prot;
      oprot.writeString(struct.file_name);
      oprot.writeI64(struct.offset);
      oprot.writeI64(struct.length);
      oprot.writeI64(struct.partition_id);
      oprot.writeI64(struct.file_length);
      oprot.writeI32(struct.file_compression.getValue());
    }

    @Override
    public void read(org.apache.thrift.protocol.TProtocol prot, THdfsFileSplit struct) throws org.apache.thrift.TException {
      TTupleProtocol iprot = (TTupleProtocol) prot;
      struct.file_name = iprot.readString();
      struct.setFile_nameIsSet(true);
      struct.offset = iprot.readI64();
      struct.setOffsetIsSet(true);
      struct.length = iprot.readI64();
      struct.setLengthIsSet(true);
      struct.partition_id = iprot.readI64();
      struct.setPartition_idIsSet(true);
      struct.file_length = iprot.readI64();
      struct.setFile_lengthIsSet(true);
      struct.file_compression = com.cloudera.impala.thrift.THdfsCompression.findByValue(iprot.readI32());
      struct.setFile_compressionIsSet(true);
    }
  }

}

